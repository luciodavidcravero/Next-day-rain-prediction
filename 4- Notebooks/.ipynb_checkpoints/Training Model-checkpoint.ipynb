{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08b759c",
   "metadata": {},
   "source": [
    "## Rain prediction in Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326aeae",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bf4efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder, LabelEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,precision_score, recall_score, f1_score,ConfusionMatrixDisplay,classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import optuna\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fa72b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5047e1",
   "metadata": {},
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df197d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.6</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albury</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location  Rainfall WindGustDir  WindGustSpeed WindDir9am WindDir3pm  \\\n",
       "0   Albury       0.6           W           44.0          W        WNW   \n",
       "1   Albury       0.0         WNW           44.0        NNW        WSW   \n",
       "2   Albury       0.0         WSW           46.0          W        WSW   \n",
       "3   Albury       0.0          NE           24.0         SE          E   \n",
       "4   Albury       1.0           W           41.0        ENE         NW   \n",
       "\n",
       "   Humidity9am  Humidity3pm  Pressure9am  RainToday  RainTomorrow  \n",
       "0         71.0         22.0       1007.7        0.0           0.0  \n",
       "1         44.0         25.0       1010.6        0.0           0.0  \n",
       "2         38.0         30.0       1007.6        0.0           0.0  \n",
       "3         45.0         16.0       1017.6        0.0           0.0  \n",
       "4         82.0         33.0       1010.8        0.0           0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_clean_wo_outl_wo_corr = pd.read_csv(r\"C:\\Users\\Lucio\\Documents\\Github\\Next-day-rain-prediction\\1- Data\\2- Processed\\dataframe_clean_wo_outl_wo_corr.csv\", index_col=0)\n",
    "dataframe_clean_wo_outl_wo_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c7d8c7",
   "metadata": {},
   "source": [
    "dataframe_clean_wo_outl_wo_corr characteristics:\n",
    "- Removed univariated outliers\n",
    "- Removed variables with high collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e506872",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e8f3f",
   "metadata": {},
   "source": [
    "#### Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e803742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Location_Adelaide</th>\n",
       "      <th>Location_Albany</th>\n",
       "      <th>Location_Albury</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NNW</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>44.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rainfall  WindGustSpeed  Humidity9am  Humidity3pm  Pressure9am  RainToday  \\\n",
       "0       0.6           44.0         71.0         22.0       1007.7        0.0   \n",
       "1       0.0           44.0         44.0         25.0       1010.6        0.0   \n",
       "2       0.0           46.0         38.0         30.0       1007.6        0.0   \n",
       "3       0.0           24.0         45.0         16.0       1017.6        0.0   \n",
       "4       1.0           41.0         82.0         33.0       1010.8        0.0   \n",
       "\n",
       "   RainTomorrow  Location_Adelaide  Location_Albany  Location_Albury  ...  \\\n",
       "0           0.0                  0                0                1  ...   \n",
       "1           0.0                  0                0                1  ...   \n",
       "2           0.0                  0                0                1  ...   \n",
       "3           0.0                  0                0                1  ...   \n",
       "4           0.0                  0                0                1  ...   \n",
       "\n",
       "   WindDir3pm_NNW  WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  \\\n",
       "0               0              0             0              0               0   \n",
       "1               0              0             0              0               0   \n",
       "2               0              0             0              0               0   \n",
       "3               0              0             0              0               0   \n",
       "4               0              1             0              0               0   \n",
       "\n",
       "   WindDir3pm_SSW  WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
       "0               0              0             0               1               0  \n",
       "1               0              0             0               0               1  \n",
       "2               0              0             0               0               1  \n",
       "3               0              0             0               0               0  \n",
       "4               0              0             0               0               0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_encoded = pd.get_dummies(dataframe_clean_wo_outl_wo_corr)\n",
    "dataframe_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587c530",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb19259",
   "metadata": {},
   "source": [
    "### Model Tranining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24797604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y dataframes\n",
    "X = dataframe_encoded[[c for c in dataframe_encoded if c != 'RainTomorrow']].values\n",
    "y = dataframe_encoded[['RainTomorrow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e775f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X, y,random_state=0, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79ba750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    param = {\n",
    "        \"verbosity\": 1,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),\n",
    "        #\"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        'eval_metric': 'error',  # Use error (1 - accuracy) as the evaluation metric for binary classification\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] == \"gbtree\":# or param[\"booster\"] == \"gblinear\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 1e-8, 1.0, log=True)\n",
    "        param[\"n_estimators\"] = trial.suggest_int(\"n_estimators\", 1, 1000)        \n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 64)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    '''\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 64)\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 1e-8, 1.0, log=True)\n",
    "        param[\"n_estimators\"] = trial.suggest_int(\"n_estimators\", 1, 1000) \n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "    '''\n",
    "    bst = xgb.train(param, dtrain)\n",
    "    y_pred = bst.predict(dvalid)\n",
    "    y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]  # Convert probabilities to binary predictions\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(y_val, y_pred_binary)\n",
    "    \n",
    "    return -accuracy  #An objective value linked with the Trial object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e9725a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = MinMaxScaler()\n",
    "sc_y = MinMaxScaler()\n",
    "X_sc = sc_X.fit_transform(X)\n",
    "y_sc = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8934496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sc_train, X_sc_val, y_sc_train, y_sc_val = sklearn.model_selection.train_test_split(X_sc, y_sc, random_state=0, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbeb5158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:25,749] A new study created in memory with name: no-name-c75bb56e-8c7c-45e6-895b-58de6bbd71a7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:28,400] Trial 0 finished with value: -0.8350420881212872 and parameters: {'booster': 'gbtree', 'lambda': 0.0027627675294478794, 'alpha': 9.030532144027777e-08, 'subsample': 0.003989341123380293, 'n_estimators': 337, 'max_depth': 24, 'eta': 0.009134665819853382, 'gamma': 1.3565771598841993e-07, 'grow_policy': 'depthwise'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:29,491] Trial 1 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 2.471120208429458e-08, 'alpha': 0.046843893307469596, 'subsample': 1.4244243161057073e-05, 'n_estimators': 865, 'max_depth': 34, 'eta': 0.13578917044329492, 'gamma': 0.0036636576310437835, 'grow_policy': 'lossguide'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:30,923] Trial 2 finished with value: -0.83483566136838 and parameters: {'booster': 'gbtree', 'lambda': 2.238000078812369e-06, 'alpha': 0.03962956754017319, 'subsample': 0.00047850965745067605, 'n_estimators': 832, 'max_depth': 19, 'eta': 0.001631261994634028, 'gamma': 1.9272462075623864e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:32,017] Trial 3 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 0.0014023110607134877, 'alpha': 8.171380121732629e-08, 'subsample': 3.900784839544371e-07, 'n_estimators': 228, 'max_depth': 52, 'eta': 0.0006445400096342336, 'gamma': 0.0010497695426235029, 'grow_policy': 'depthwise'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:33,004] Trial 4 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 1.2873597380855141e-06, 'alpha': 1.7365447887985792e-07, 'subsample': 3.025779814382656e-06, 'n_estimators': 372, 'max_depth': 39, 'eta': 9.138271792830982e-08, 'gamma': 0.0003246062073110227, 'grow_policy': 'lossguide'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:34,108] Trial 5 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 6.36175798753497e-08, 'alpha': 7.95936242522374e-07, 'subsample': 1.0515018278731473e-05, 'n_estimators': 1, 'max_depth': 60, 'eta': 0.0004889301316886351, 'gamma': 1.4375991236156355e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:35,157] Trial 6 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 1.1055549353601064e-07, 'alpha': 0.1536323212283759, 'subsample': 2.4923729510484223e-08, 'n_estimators': 784, 'max_depth': 13, 'eta': 0.3714214372989, 'gamma': 4.0434780849169694e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:36,124] Trial 7 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 4.7509295986508734e-07, 'alpha': 1.3510367982151932e-08, 'subsample': 1.3390993105433518e-08, 'n_estimators': 574, 'max_depth': 14, 'eta': 5.088869506315166e-06, 'gamma': 0.0034877600261929336, 'grow_policy': 'depthwise'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:37,090] Trial 8 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 2.384099428978859e-05, 'alpha': 0.15232653727383266, 'subsample': 1.486002499482311e-08, 'n_estimators': 807, 'max_depth': 10, 'eta': 0.012077886002626246, 'gamma': 9.633634508606543e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:38,123] Trial 9 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 1.4656826451928042e-08, 'alpha': 1.2100794932721145e-06, 'subsample': 7.553947027554905e-08, 'n_estimators': 607, 'max_depth': 54, 'eta': 2.1599463192097523e-06, 'gamma': 8.339740224292807e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:39,322] Trial 10 finished with value: -0.8259134383816142 and parameters: {'booster': 'gbtree', 'lambda': 0.25252409181757013, 'alpha': 5.045320489437193e-05, 'subsample': 0.04594564374942321, 'n_estimators': 185, 'max_depth': 1, 'eta': 0.02580748841307193, 'gamma': 0.9981440284478406, 'grow_policy': 'depthwise'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:41,202] Trial 11 finished with value: -0.8299731645221221 and parameters: {'booster': 'gbtree', 'lambda': 0.00040661183206323583, 'alpha': 0.0024767000594946107, 'subsample': 0.0012314023010506201, 'n_estimators': 445, 'max_depth': 24, 'eta': 0.0029277625612860415, 'gamma': 9.098854903282147e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:42,740] Trial 12 finished with value: -0.8313722791807151 and parameters: {'booster': 'gbtree', 'lambda': 1.5639591070208627e-05, 'alpha': 3.069811564885136e-05, 'subsample': 0.0006174964351598703, 'n_estimators': 994, 'max_depth': 25, 'eta': 6.181553987731658e-05, 'gamma': 4.480193261544629e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:47,309] Trial 13 finished with value: -0.7655909539209614 and parameters: {'booster': 'gbtree', 'lambda': 0.008284790595296384, 'alpha': 0.0015530035066372969, 'subsample': 0.041124345818796086, 'n_estimators': 676, 'max_depth': 24, 'eta': 0.7339849472242173, 'gamma': 5.254777240178458e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: -0.8350420881212872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:35:59,003] Trial 14 finished with value: -0.8441019289433244 and parameters: {'booster': 'gbtree', 'lambda': 5.503364712626407e-06, 'alpha': 0.9450088535951114, 'subsample': 0.725362881616662, 'n_estimators': 332, 'max_depth': 41, 'eta': 0.011355936900811325, 'gamma': 8.321026992375705e-07, 'grow_policy': 'lossguide'}. Best is trial 14 with value: -0.8441019289433244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:36:17,446] Trial 15 finished with value: -0.8419000435789812 and parameters: {'booster': 'gbtree', 'lambda': 0.0001064304639682045, 'alpha': 6.677554153138328e-06, 'subsample': 0.562805916777869, 'n_estimators': 298, 'max_depth': 41, 'eta': 0.027661369442186844, 'gamma': 1.1090720649466408e-08, 'grow_policy': 'depthwise'}. Best is trial 14 with value: -0.8441019289433244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:36:36,687] Trial 16 finished with value: -0.8406844193674167 and parameters: {'booster': 'gbtree', 'lambda': 7.313612924958608e-05, 'alpha': 6.503266957143363e-06, 'subsample': 0.6646803201620943, 'n_estimators': 121, 'max_depth': 44, 'eta': 0.08736300797319703, 'gamma': 1.2043994523796056e-08, 'grow_policy': 'lossguide'}. Best is trial 14 with value: -0.8441019289433244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:36:47,463] Trial 17 finished with value: -0.8451799353196174 and parameters: {'booster': 'gbtree', 'lambda': 7.82496132019947e-06, 'alpha': 0.885383250911391, 'subsample': 0.5130725001909233, 'n_estimators': 284, 'max_depth': 44, 'eta': 0.059460048221478726, 'gamma': 1.3069558461007474e-06, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:36:51,883] Trial 18 finished with value: -0.839422922544095 and parameters: {'booster': 'gbtree', 'lambda': 4.51652304868137e-06, 'alpha': 0.6790620639790343, 'subsample': 0.03946306528296284, 'n_estimators': 481, 'max_depth': 48, 'eta': 0.10464003500919963, 'gamma': 1.3506514797924652e-05, 'grow_policy': 'lossguide'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:37:06,684] Trial 19 finished with value: -0.8341246358861442 and parameters: {'booster': 'gbtree', 'lambda': 3.637200188202458e-07, 'alpha': 0.5870484446158166, 'subsample': 0.9947875195007188, 'n_estimators': 113, 'max_depth': 34, 'eta': 0.7144727821390991, 'gamma': 1.1341817483709955e-06, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:37:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:37:10,192] Trial 20 finished with value: -0.8382990435560449 and parameters: {'booster': 'gbtree', 'lambda': 5.6418277917611375e-06, 'alpha': 0.004416721292540735, 'subsample': 0.00845371597667377, 'n_estimators': 421, 'max_depth': 64, 'eta': 0.003545887038171034, 'gamma': 1.1986690920192988e-05, 'grow_policy': 'lossguide'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:37:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:37:24,071] Trial 21 finished with value: -0.8427257505906098 and parameters: {'booster': 'gbtree', 'lambda': 0.00010861950882771133, 'alpha': 0.00029994808655373127, 'subsample': 0.3538814511748099, 'n_estimators': 287, 'max_depth': 43, 'eta': 0.02754261117857274, 'gamma': 4.678410123213796e-07, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:37:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:37:33,022] Trial 22 finished with value: -0.8408679098144453 and parameters: {'booster': 'gbtree', 'lambda': 2.0205827385176702e-05, 'alpha': 0.0006142537969146693, 'subsample': 0.1749730134649326, 'n_estimators': 274, 'max_depth': 47, 'eta': 0.042788165960413314, 'gamma': 6.028489459548962e-07, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:37:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:37:40,297] Trial 23 finished with value: -0.840615610449781 and parameters: {'booster': 'gbtree', 'lambda': 0.00010947168632476244, 'alpha': 0.01401644114398869, 'subsample': 0.1386040944299978, 'n_estimators': 133, 'max_depth': 38, 'eta': 0.008401622171663048, 'gamma': 4.6756868904668984e-05, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:37:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:37:50,249] Trial 24 finished with value: -0.833918209133237 and parameters: {'booster': 'gbtree', 'lambda': 1.8722539872920446e-06, 'alpha': 0.00029683405669519346, 'subsample': 0.17631617286171278, 'n_estimators': 358, 'max_depth': 54, 'eta': 0.18406554587292334, 'gamma': 5.138993912376526e-07, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:37:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:37:53,789] Trial 25 finished with value: -0.8358448588270373 and parameters: {'booster': 'gbtree', 'lambda': 1.0625478282341933e-05, 'alpha': 0.009066904632847468, 'subsample': 0.010457834665691423, 'n_estimators': 48, 'max_depth': 30, 'eta': 0.040397839935231765, 'gamma': 2.1125257712703806e-06, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:37:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:38:05,548] Trial 26 finished with value: -0.7736186609784628 and parameters: {'booster': 'gbtree', 'lambda': 6.515091240721063e-07, 'alpha': 0.00023797844228759876, 'subsample': 0.3076869356296905, 'n_estimators': 224, 'max_depth': 45, 'eta': 0.8355841211335443, 'gamma': 3.4799306677061696e-07, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:38:19,893] Trial 27 finished with value: -0.8448588270373174 and parameters: {'booster': 'gbtree', 'lambda': 5.1089045021982234e-05, 'alpha': 0.9865403574347783, 'subsample': 0.9456724922896605, 'n_estimators': 559, 'max_depth': 31, 'eta': 0.15356564870013167, 'gamma': 2.4039670457833144e-06, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:38:35,341] Trial 28 finished with value: -0.8443312920021101 and parameters: {'booster': 'gbtree', 'lambda': 4.359260209005445e-06, 'alpha': 0.9727887334512185, 'subsample': 0.8791975434443149, 'n_estimators': 544, 'max_depth': 29, 'eta': 0.18802228746120614, 'gamma': 3.928172942910947e-05, 'grow_policy': 'lossguide'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-21 19:38:38,346] Trial 29 finished with value: -0.8141929860776623 and parameters: {'booster': 'gbtree', 'lambda': 3.357244031832335e-05, 'alpha': 0.1898117939282201, 'subsample': 0.0037847349364593754, 'n_estimators': 578, 'max_depth': 29, 'eta': 0.2747802029336958, 'gamma': 4.234655297086859e-05, 'grow_policy': 'depthwise'}. Best is trial 17 with value: -0.8451799353196174.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'lambda': 7.82496132019947e-06,\n",
       " 'alpha': 0.885383250911391,\n",
       " 'subsample': 0.5130725001909233,\n",
       " 'n_estimators': 284,\n",
       " 'max_depth': 44,\n",
       " 'eta': 0.059460048221478726,\n",
       " 'gamma': 1.3069558461007474e-06,\n",
       " 'grow_policy': 'depthwise'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_xgb = optuna.create_study()\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "study_xgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16390390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'lambda': 7.82496132019947e-06,\n",
       " 'alpha': 0.885383250911391,\n",
       " 'subsample': 0.5130725001909233,\n",
       " 'n_estimators': 284,\n",
       " 'max_depth': 44,\n",
       " 'eta': 0.059460048221478726,\n",
       " 'gamma': 1.3069558461007474e-06,\n",
       " 'grow_policy': 'depthwise'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = study_xgb.best_params\n",
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bee20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_sc_train, y_sc_train)\n",
    "dtest = xgb.DMatrix(X_sc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103032e7",
   "metadata": {},
   "source": [
    "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=50,\n",
    "    verbose_eval=200, show_stdv=False)\n",
    "cv_output[['train-rmse-mean', 'test-rmse-mean']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4843392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucio\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:43:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.66162\n",
      "[1]\tvalidation_0-logloss:0.63355\n",
      "[2]\tvalidation_0-logloss:0.60872\n",
      "[3]\tvalidation_0-logloss:0.58631\n",
      "[4]\tvalidation_0-logloss:0.56614\n",
      "[5]\tvalidation_0-logloss:0.54785\n",
      "[6]\tvalidation_0-logloss:0.53145\n",
      "[7]\tvalidation_0-logloss:0.51633\n",
      "[8]\tvalidation_0-logloss:0.50267\n",
      "[9]\tvalidation_0-logloss:0.49028\n",
      "[10]\tvalidation_0-logloss:0.47891\n",
      "[11]\tvalidation_0-logloss:0.46856\n",
      "[12]\tvalidation_0-logloss:0.45896\n",
      "[13]\tvalidation_0-logloss:0.45009\n",
      "[14]\tvalidation_0-logloss:0.44203\n",
      "[15]\tvalidation_0-logloss:0.43463\n",
      "[16]\tvalidation_0-logloss:0.42813\n",
      "[17]\tvalidation_0-logloss:0.42201\n",
      "[18]\tvalidation_0-logloss:0.41635\n",
      "[19]\tvalidation_0-logloss:0.41118\n",
      "[20]\tvalidation_0-logloss:0.40630\n",
      "[21]\tvalidation_0-logloss:0.40202\n",
      "[22]\tvalidation_0-logloss:0.39800\n",
      "[23]\tvalidation_0-logloss:0.39441\n",
      "[24]\tvalidation_0-logloss:0.39109\n",
      "[25]\tvalidation_0-logloss:0.38798\n",
      "[26]\tvalidation_0-logloss:0.38508\n",
      "[27]\tvalidation_0-logloss:0.38247\n",
      "[28]\tvalidation_0-logloss:0.38014\n",
      "[29]\tvalidation_0-logloss:0.37787\n",
      "[30]\tvalidation_0-logloss:0.37581\n",
      "[31]\tvalidation_0-logloss:0.37393\n",
      "[32]\tvalidation_0-logloss:0.37210\n",
      "[33]\tvalidation_0-logloss:0.37046\n",
      "[34]\tvalidation_0-logloss:0.36890\n",
      "[35]\tvalidation_0-logloss:0.36745\n",
      "[36]\tvalidation_0-logloss:0.36625\n",
      "[37]\tvalidation_0-logloss:0.36506\n",
      "[38]\tvalidation_0-logloss:0.36414\n",
      "[39]\tvalidation_0-logloss:0.36316\n",
      "[40]\tvalidation_0-logloss:0.36237\n",
      "[41]\tvalidation_0-logloss:0.36152\n",
      "[42]\tvalidation_0-logloss:0.36079\n",
      "[43]\tvalidation_0-logloss:0.36007\n",
      "[44]\tvalidation_0-logloss:0.35943\n",
      "[45]\tvalidation_0-logloss:0.35883\n",
      "[46]\tvalidation_0-logloss:0.35836\n",
      "[47]\tvalidation_0-logloss:0.35780\n",
      "[48]\tvalidation_0-logloss:0.35728\n",
      "[49]\tvalidation_0-logloss:0.35685\n",
      "[50]\tvalidation_0-logloss:0.35643\n",
      "[51]\tvalidation_0-logloss:0.35599\n",
      "[52]\tvalidation_0-logloss:0.35583\n",
      "[53]\tvalidation_0-logloss:0.35553\n",
      "[54]\tvalidation_0-logloss:0.35531\n",
      "[55]\tvalidation_0-logloss:0.35503\n",
      "[56]\tvalidation_0-logloss:0.35485\n",
      "[57]\tvalidation_0-logloss:0.35469\n",
      "[58]\tvalidation_0-logloss:0.35463\n",
      "[59]\tvalidation_0-logloss:0.35458\n",
      "[60]\tvalidation_0-logloss:0.35446\n",
      "[61]\tvalidation_0-logloss:0.35442\n",
      "[62]\tvalidation_0-logloss:0.35428\n",
      "[63]\tvalidation_0-logloss:0.35410\n",
      "[64]\tvalidation_0-logloss:0.35404\n",
      "[65]\tvalidation_0-logloss:0.35401\n",
      "[66]\tvalidation_0-logloss:0.35391\n",
      "[67]\tvalidation_0-logloss:0.35373\n",
      "[68]\tvalidation_0-logloss:0.35377\n",
      "[69]\tvalidation_0-logloss:0.35368\n",
      "[70]\tvalidation_0-logloss:0.35353\n",
      "[71]\tvalidation_0-logloss:0.35358\n",
      "[72]\tvalidation_0-logloss:0.35361\n",
      "[73]\tvalidation_0-logloss:0.35370\n",
      "[74]\tvalidation_0-logloss:0.35370\n",
      "[75]\tvalidation_0-logloss:0.35372\n",
      "[76]\tvalidation_0-logloss:0.35384\n",
      "[77]\tvalidation_0-logloss:0.35385\n",
      "[78]\tvalidation_0-logloss:0.35387\n",
      "[79]\tvalidation_0-logloss:0.35391\n",
      "[80]\tvalidation_0-logloss:0.35399\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(alpha=0.885383250911391, base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "              callbacks=None, colsample_bylevel=1, colsample_bynode=1,\n",
       "              colsample_bytree=1, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.059460048221478726,\n",
       "              eval_metric=None, gamma=1.3069558461007474e-06, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, lambda=7.82496132019947e-06,\n",
       "              learning_rate=0.0594600476, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=44, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=284,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.885383250911391, base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "              callbacks=None, colsample_bylevel=1, colsample_bynode=1,\n",
       "              colsample_bytree=1, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.059460048221478726,\n",
       "              eval_metric=None, gamma=1.3069558461007474e-06, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, lambda=7.82496132019947e-06,\n",
       "              learning_rate=0.0594600476, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=44, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=284,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(alpha=0.885383250911391, base_score=0.5, booster='gbtree',\n",
       "              callbacks=None, colsample_bylevel=1, colsample_bynode=1,\n",
       "              colsample_bytree=1, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.059460048221478726,\n",
       "              eval_metric=None, gamma=1.3069558461007474e-06, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', lambda=7.82496132019947e-06,\n",
       "              learning_rate=0.0594600476, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=44, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=284,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#num_boost_rounds = len(cv_output)\n",
    "num_boost_rounds = 50\n",
    "#print(num_boost_rounds)\n",
    "\n",
    "model = XGBClassifier(**xgb_params, silent=0)\n",
    "\n",
    "model.fit(X_sc_train, y_sc_train, eval_set=[(X_sc_val, y_sc_val)], early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "#model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "582e0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_sc_val)\n",
    "#threshold = 0.5\n",
    "#y_binary_predicted = np.where(y_predicted >= threshold, 1, 0)\n",
    "#y_binary_predicted\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fe12133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[32302  1817]\n",
      " [ 4702  4778]]\n",
      "Accuracy: 0.8504782219775683\n",
      "Precision: 0.7244882486732374\n",
      "Recall: 0.5040084388185654\n",
      "F1-Score: 0.5944634525660965\n",
      "ROC AUC: 0.7253768270472556\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_sc_val, y_predicted)\n",
    "\n",
    "accuracy = accuracy_score(y_sc_val, y_predicted)\n",
    "precision = precision_score(y_sc_val, y_predicted)\n",
    "recall = recall_score(y_sc_val, y_predicted)\n",
    "f1 = f1_score(y_sc_val, y_predicted)\n",
    "roc_auc = roc_auc_score(y_sc_val, y_predicted)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
