{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08b759c",
   "metadata": {},
   "source": [
    "## Rain prediction in Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326aeae",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5bf4efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,precision_score, recall_score, f1_score,ConfusionMatrixDisplay,classification_report\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "import sklearn\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fa72b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5047e1",
   "metadata": {},
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5df197d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.6</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albury</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albury</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location  Rainfall WindGustDir  WindGustSpeed WindDir9am WindDir3pm  \\\n",
       "0   Albury       0.6           W           44.0          W        WNW   \n",
       "1   Albury       0.0         WNW           44.0        NNW        WSW   \n",
       "2   Albury       0.0         WSW           46.0          W        WSW   \n",
       "3   Albury       0.0          NE           24.0         SE          E   \n",
       "4   Albury       1.0           W           41.0        ENE         NW   \n",
       "\n",
       "   Humidity9am  Humidity3pm  Pressure9am  RainToday  RainTomorrow  \n",
       "0         71.0         22.0       1007.7        0.0           0.0  \n",
       "1         44.0         25.0       1010.6        0.0           0.0  \n",
       "2         38.0         30.0       1007.6        0.0           0.0  \n",
       "3         45.0         16.0       1017.6        0.0           0.0  \n",
       "4         82.0         33.0       1010.8        0.0           0.0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_clean_wo_outl_wo_corr = pd.read_csv(r\"C:\\Users\\Lucio\\Documents\\Github\\Next-day-rain-prediction\\1- Data\\2- Processed\\dataframe_clean_wo_outl_wo_corr.csv\", index_col=0)\n",
    "dataframe_clean_wo_outl_wo_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c7d8c7",
   "metadata": {},
   "source": [
    "dataframe_clean_wo_outl_wo_corr characteristics:\n",
    "- Removed univariated outliers\n",
    "- Removed variables with high collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e506872",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e8f3f",
   "metadata": {},
   "source": [
    "#### Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e803742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Location_Adelaide</th>\n",
       "      <th>Location_Albany</th>\n",
       "      <th>Location_Albury</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NNW</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>44.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rainfall  WindGustSpeed  Humidity9am  Humidity3pm  Pressure9am  RainToday  \\\n",
       "0       0.6           44.0         71.0         22.0       1007.7        0.0   \n",
       "1       0.0           44.0         44.0         25.0       1010.6        0.0   \n",
       "2       0.0           46.0         38.0         30.0       1007.6        0.0   \n",
       "3       0.0           24.0         45.0         16.0       1017.6        0.0   \n",
       "4       1.0           41.0         82.0         33.0       1010.8        0.0   \n",
       "\n",
       "   RainTomorrow  Location_Adelaide  Location_Albany  Location_Albury  ...  \\\n",
       "0           0.0                  0                0                1  ...   \n",
       "1           0.0                  0                0                1  ...   \n",
       "2           0.0                  0                0                1  ...   \n",
       "3           0.0                  0                0                1  ...   \n",
       "4           0.0                  0                0                1  ...   \n",
       "\n",
       "   WindDir3pm_NNW  WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  \\\n",
       "0               0              0             0              0               0   \n",
       "1               0              0             0              0               0   \n",
       "2               0              0             0              0               0   \n",
       "3               0              0             0              0               0   \n",
       "4               0              1             0              0               0   \n",
       "\n",
       "   WindDir3pm_SSW  WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
       "0               0              0             0               1               0  \n",
       "1               0              0             0               0               1  \n",
       "2               0              0             0               0               1  \n",
       "3               0              0             0               0               0  \n",
       "4               0              0             0               0               0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_encoded = pd.get_dummies(dataframe_clean_wo_outl_wo_corr)\n",
    "dataframe_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587c530",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb19259",
   "metadata": {},
   "source": [
    "### Model Tranining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24797604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y dataframes\n",
    "X = dataframe_encoded[[c for c in dataframe_encoded if c != 'RainTomorrow']].values\n",
    "y = dataframe_encoded[['RainTomorrow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e775f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X, y,random_state=0, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e79ba750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    param = {\n",
    "        \"verbosity\": 1,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),\n",
    "        #\"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        'eval_metric': 'error',  # Use error (1 - accuracy) as the evaluation metric for binary classification\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] == \"gbtree\":# or param[\"booster\"] == \"gblinear\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 1e-8, 1.0, log=True)\n",
    "        param[\"n_estimators\"] = trial.suggest_int(\"n_estimators\", 1, 1000)        \n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 64)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    '''\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 64)\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 1e-8, 1.0, log=True)\n",
    "        param[\"n_estimators\"] = trial.suggest_int(\"n_estimators\", 1, 1000) \n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "    '''\n",
    "    bst = xgb.train(param, dtrain)\n",
    "    y_pred = bst.predict(dvalid)\n",
    "    y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]  # Convert probabilities to binary predictions\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(y_val, y_pred_binary)\n",
    "    \n",
    "    return -accuracy  #An objective value linked with the Trial object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0e9725a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = MinMaxScaler()\n",
    "sc_y = MinMaxScaler()\n",
    "X_sc = sc_X.fit_transform(X)\n",
    "y_sc = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8934496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sc_train, X_sc_val, y_sc_train, y_sc_val = sklearn.model_selection.train_test_split(X_sc, y_sc, random_state=0, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dbeb5158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:16,839] A new study created in memory with name: no-name-16ecd932-2e4f-4ef0-8053-489f93bd0e5b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:17,901] Trial 0 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 8.77008966274251e-08, 'alpha': 1.1217741748904297e-05, 'subsample': 1.9649998899421286e-07, 'n_estimators': 732, 'max_depth': 5, 'eta': 0.0006822404157729144, 'gamma': 0.0008734726998205522, 'grow_policy': 'lossguide'}. Best is trial 0 with value: -0.21743617972889287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:19,739] Trial 1 finished with value: -0.8299502282162435 and parameters: {'booster': 'gbtree', 'lambda': 0.5555176828381193, 'alpha': 0.0007421043368172693, 'subsample': 0.001492848062843864, 'n_estimators': 159, 'max_depth': 38, 'eta': 0.0010424615489997226, 'gamma': 0.3984763008683728, 'grow_policy': 'depthwise'}. Best is trial 1 with value: -0.8299502282162435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:23,066] Trial 2 finished with value: -0.8401110117204523 and parameters: {'booster': 'gbtree', 'lambda': 7.365935438458266e-07, 'alpha': 0.006231331135425295, 'subsample': 0.05641821348014511, 'n_estimators': 727, 'max_depth': 13, 'eta': 1.5917266558849022e-07, 'gamma': 0.00029412389046588227, 'grow_policy': 'depthwise'}. Best is trial 2 with value: -0.8401110117204523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:24,330] Trial 3 finished with value: -0.8258675657698571 and parameters: {'booster': 'gbtree', 'lambda': 0.14817875296261765, 'alpha': 2.3020459262895613e-07, 'subsample': 0.00021146431522850825, 'n_estimators': 285, 'max_depth': 46, 'eta': 0.3657024166805621, 'gamma': 0.2302963069408283, 'grow_policy': 'depthwise'}. Best is trial 2 with value: -0.8401110117204523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:25,373] Trial 4 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 4.606493305929284e-07, 'alpha': 3.823747639073027e-06, 'subsample': 2.361729377037714e-07, 'n_estimators': 347, 'max_depth': 45, 'eta': 2.7918813701002797e-06, 'gamma': 0.00012446861933106102, 'grow_policy': 'depthwise'}. Best is trial 2 with value: -0.8401110117204523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:26,707] Trial 5 finished with value: -0.8165783618890341 and parameters: {'booster': 'gbtree', 'lambda': 3.030133181529254e-07, 'alpha': 9.449980828229993e-08, 'subsample': 0.00036328449931747063, 'n_estimators': 769, 'max_depth': 8, 'eta': 1.333120939075633e-07, 'gamma': 2.7639440485035454e-06, 'grow_policy': 'depthwise'}. Best is trial 2 with value: -0.8401110117204523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:27,775] Trial 6 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 9.529020163376382e-05, 'alpha': 4.217470345304875e-08, 'subsample': 5.315695988654931e-07, 'n_estimators': 958, 'max_depth': 1, 'eta': 0.0874145922972552, 'gamma': 4.435579179747153e-06, 'grow_policy': 'depthwise'}. Best is trial 2 with value: -0.8401110117204523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:30,242] Trial 7 finished with value: -0.8346062983095942 and parameters: {'booster': 'gbtree', 'lambda': 0.004550553543937225, 'alpha': 0.04495658201585405, 'subsample': 0.004866587578505281, 'n_estimators': 496, 'max_depth': 57, 'eta': 2.1208847880378816e-07, 'gamma': 0.000468650837625833, 'grow_policy': 'lossguide'}. Best is trial 2 with value: -0.8401110117204523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:31,399] Trial 8 finished with value: -0.8123810179132549 and parameters: {'booster': 'gbtree', 'lambda': 1.1674979935650458e-07, 'alpha': 0.483818242518279, 'subsample': 0.000173558408934001, 'n_estimators': 917, 'max_depth': 12, 'eta': 0.037070889822082224, 'gamma': 0.715627407369396, 'grow_policy': 'lossguide'}. Best is trial 2 with value: -0.8401110117204523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:32,392] Trial 9 finished with value: -0.21743617972889287 and parameters: {'booster': 'gbtree', 'lambda': 0.055110768063213134, 'alpha': 0.0011784009855167032, 'subsample': 3.244046259420569e-05, 'n_estimators': 107, 'max_depth': 7, 'eta': 0.20824428219690874, 'gamma': 3.115713162856081e-08, 'grow_policy': 'depthwise'}. Best is trial 2 with value: -0.8401110117204523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:43,102] Trial 10 finished with value: -0.7916236610931443 and parameters: {'booster': 'gbtree', 'lambda': 9.38396293799864e-06, 'alpha': 0.009472099080019789, 'subsample': 0.45750421414841697, 'n_estimators': 627, 'max_depth': 22, 'eta': 1.7564108713463755e-08, 'gamma': 0.011178589924677355, 'grow_policy': 'lossguide'}. Best is trial 2 with value: -0.8401110117204523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:46:47,992] Trial 11 finished with value: -0.840776164590931 and parameters: {'booster': 'gbtree', 'lambda': 0.0029824892850778707, 'alpha': 0.0783349157292753, 'subsample': 0.04678768154292298, 'n_estimators': 516, 'max_depth': 61, 'eta': 2.152927627699066e-06, 'gamma': 0.0032861754498514097, 'grow_policy': 'lossguide'}. Best is trial 11 with value: -0.840776164590931.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:46:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:47:00,411] Trial 12 finished with value: -0.84320741301406 and parameters: {'booster': 'gbtree', 'lambda': 0.0012377444523354998, 'alpha': 0.7089483217167514, 'subsample': 0.7651611262582064, 'n_estimators': 536, 'max_depth': 64, 'eta': 7.482312027701708e-06, 'gamma': 0.0026281706683214143, 'grow_policy': 'lossguide'}. Best is trial 12 with value: -0.84320741301406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:47:13,957] Trial 13 finished with value: -0.8428174958141241 and parameters: {'booster': 'gbtree', 'lambda': 0.0020943279013198326, 'alpha': 0.4643305542966304, 'subsample': 0.8438738346740243, 'n_estimators': 512, 'max_depth': 64, 'eta': 1.0365825077862987e-05, 'gamma': 0.007993524109420945, 'grow_policy': 'lossguide'}. Best is trial 12 with value: -0.84320741301406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:47:27,821] Trial 14 finished with value: -0.8420835340260098 and parameters: {'booster': 'gbtree', 'lambda': 0.0006229155607056884, 'alpha': 0.594271836051047, 'subsample': 0.8598594526946035, 'n_estimators': 426, 'max_depth': 63, 'eta': 2.545297819257957e-05, 'gamma': 0.043043568242465864, 'grow_policy': 'lossguide'}. Best is trial 12 with value: -0.84320741301406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:47:39,783] Trial 15 finished with value: -0.8444230372256244 and parameters: {'booster': 'gbtree', 'lambda': 0.00010894967179941824, 'alpha': 0.8102337065208637, 'subsample': 0.7066397234601337, 'n_estimators': 595, 'max_depth': 52, 'eta': 3.0381908008215484e-05, 'gamma': 0.012962072325710412, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:47:44,737] Trial 16 finished with value: -0.8408679098144453 and parameters: {'booster': 'gbtree', 'lambda': 3.306478326985814e-05, 'alpha': 0.033466958647240086, 'subsample': 0.03667428552940554, 'n_estimators': 634, 'max_depth': 52, 'eta': 0.0001355281327151393, 'gamma': 0.0460355725124636, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:47:47,141] Trial 17 finished with value: -0.8376568269914447 and parameters: {'booster': 'gbtree', 'lambda': 0.00035870860821299007, 'alpha': 0.6631791112206207, 'subsample': 0.0074588528315484405, 'n_estimators': 277, 'max_depth': 29, 'eta': 0.00018423787432591743, 'gamma': 0.002528986940931038, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:47:52,701] Trial 18 finished with value: -0.8412119544026239 and parameters: {'booster': 'gbtree', 'lambda': 5.327523376485084e-06, 'alpha': 0.0001918862453361102, 'subsample': 0.07466158209923658, 'n_estimators': 628, 'max_depth': 53, 'eta': 0.004088193413484447, 'gamma': 0.05802621792517436, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:48:01,408] Trial 19 finished with value: -0.8419229798848598 and parameters: {'booster': 'gbtree', 'lambda': 0.026267699586674947, 'alpha': 0.07870941919969882, 'subsample': 0.18856405935428153, 'n_estimators': 839, 'max_depth': 44, 'eta': 3.97194742902013e-05, 'gamma': 4.469672194824112e-05, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:48:10,908] Trial 20 finished with value: -0.8422211518612812 and parameters: {'booster': 'gbtree', 'lambda': 0.00013397876450705213, 'alpha': 0.0032651207961731763, 'subsample': 0.23386408267710618, 'n_estimators': 403, 'max_depth': 35, 'eta': 4.8595707136982075e-06, 'gamma': 0.012971765036874736, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:48:23,177] Trial 21 finished with value: -0.84368907543751 and parameters: {'booster': 'gbtree', 'lambda': 0.0017651459016988463, 'alpha': 0.8697576274523481, 'subsample': 0.7128885461711008, 'n_estimators': 544, 'max_depth': 64, 'eta': 1.4309136387964336e-05, 'gamma': 0.004370842320230877, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:48:26,727] Trial 22 finished with value: -0.836234776026973 and parameters: {'booster': 'gbtree', 'lambda': 1.5888055577469262e-08, 'alpha': 0.12636999373079552, 'subsample': 0.014607638485367027, 'n_estimators': 606, 'max_depth': 56, 'eta': 3.349344227385344e-05, 'gamma': 0.0017655371481752485, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:48:33,949] Trial 23 finished with value: -0.8430239225670314 and parameters: {'booster': 'gbtree', 'lambda': 0.011471231880765608, 'alpha': 0.9559140735821122, 'subsample': 0.19471143260544768, 'n_estimators': 550, 'max_depth': 49, 'eta': 1.5212007101058674e-06, 'gamma': 0.0795248965520634, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:48:53,533] Trial 24 finished with value: -0.8376109543796876 and parameters: {'booster': 'gbtree', 'lambda': 0.0009030934366751695, 'alpha': 0.0114360667781122, 'subsample': 0.8957522058602349, 'n_estimators': 412, 'max_depth': 58, 'eta': 1.0549084472822241e-05, 'gamma': 0.00728734246803576, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:48:59,497] Trial 25 finished with value: -0.841854170967224 and parameters: {'booster': 'gbtree', 'lambda': 0.007710519445196312, 'alpha': 0.16834246352554172, 'subsample': 0.10225463583725032, 'n_estimators': 1, 'max_depth': 64, 'eta': 0.00014657892380767878, 'gamma': 0.0011957406499451709, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:49:02,842] Trial 26 finished with value: -0.837106355650359 and parameters: {'booster': 'gbtree', 'lambda': 0.0002867576735372196, 'alpha': 0.16828444141674087, 'subsample': 0.013146722708631674, 'n_estimators': 708, 'max_depth': 41, 'eta': 8.253541326333117e-07, 'gamma': 0.017128504284003903, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:49:13,378] Trial 27 finished with value: -0.8435514576022386 and parameters: {'booster': 'gbtree', 'lambda': 0.0009447085903527602, 'alpha': 0.019887439692009738, 'subsample': 0.2604286034940646, 'n_estimators': 819, 'max_depth': 51, 'eta': 1.162844432261534e-05, 'gamma': 0.0981689814331377, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:49:21,451] Trial 28 finished with value: -0.8408679098144453 and parameters: {'booster': 'gbtree', 'lambda': 5.188265350177944e-05, 'alpha': 0.022876767390529223, 'subsample': 0.174385934313364, 'n_estimators': 862, 'max_depth': 50, 'eta': 5.47692247335079e-05, 'gamma': 0.15175153830068486, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 21:49:25,598] Trial 29 finished with value: -0.8390100690382807 and parameters: {'booster': 'gbtree', 'lambda': 0.0002532428960567562, 'alpha': 0.03583672303456677, 'subsample': 0.027156908365722546, 'n_estimators': 792, 'max_depth': 24, 'eta': 0.00033496619805896644, 'gamma': 0.25577496211706585, 'grow_policy': 'lossguide'}. Best is trial 15 with value: -0.8444230372256244.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'lambda': 0.00010894967179941824,\n",
       " 'alpha': 0.8102337065208637,\n",
       " 'subsample': 0.7066397234601337,\n",
       " 'n_estimators': 595,\n",
       " 'max_depth': 52,\n",
       " 'eta': 3.0381908008215484e-05,\n",
       " 'gamma': 0.012962072325710412,\n",
       " 'grow_policy': 'lossguide'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_xgb = optuna.create_study()\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "study_xgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "16390390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'lambda': 0.00010894967179941824,\n",
       " 'alpha': 0.8102337065208637,\n",
       " 'subsample': 0.7066397234601337,\n",
       " 'n_estimators': 595,\n",
       " 'max_depth': 52,\n",
       " 'eta': 3.0381908008215484e-05,\n",
       " 'gamma': 0.012962072325710412,\n",
       " 'grow_policy': 'lossguide'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = study_xgb.best_params\n",
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8bee20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_sc_train, y_sc_train)\n",
    "dtest = xgb.DMatrix(X_sc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103032e7",
   "metadata": {},
   "source": [
    "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=50,\n",
    "    verbose_eval=200, show_stdv=False)\n",
    "cv_output[['train-rmse-mean', 'test-rmse-mean']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a4843392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[21:50:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#num_boost_rounds = len(cv_output)\n",
    "num_boost_rounds = 50\n",
    "print(num_boost_rounds)\n",
    "\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "582e0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(dtest)\n",
    "threshold = 0.5\n",
    "y_binary_predicted = np.where(y_predicted >= threshold, 1, 0)\n",
    "y_binary_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0fe12133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[32295  1824]\n",
      " [ 4856  4624]]\n",
      "Accuracy: 0.8467854767311177\n",
      "Precision: 0.71712158808933\n",
      "Recall: 0.4877637130801688\n",
      "F1-Score: 0.5806127574083375\n",
      "ROC AUC: 0.7171518820390733\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_sc_val, y_predicted_binary)\n",
    "\n",
    "accuracy = accuracy_score(y_sc_val, y_predicted_binary)\n",
    "precision = precision_score(y_sc_val, y_predicted_binary)\n",
    "recall = recall_score(y_sc_val, y_predicted_binary)\n",
    "f1 = f1_score(y_sc_val, y_predicted_binary)\n",
    "roc_auc = roc_auc_score(y_sc_val, y_predicted_binary)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a46460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
